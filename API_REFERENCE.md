# RedTeamer Zero API Reference

This document provides detailed API documentation for the RedTeamer Zero framework.

## Core Modules

### 1. Orchestration (`rtz.orchestration`)

#### `langgraph_flow` Module

##### `RTZState`

A TypedDict defining the state schema for the LangGraph flow.

**Attributes:**

- `seed` (int): Random seed for reproducibility
- `budget_usd` (float): Remaining budget in USD
- `scenario` (dict): The current scenario being tested
- `attempt` (int): Current attempt number
- `attack_prompt` (str | None): The attack prompt generated by the attacker
- `defense_actions` (list[dict]): List of defense actions taken
- `model_output` (str | None): The model's response
- `judgement` (dict | None): The judge's evaluation
- `learner_state` (dict): State maintained by the learner
- `costs` (dict): Dictionary tracking costs of operations
- `done` (bool): Whether the flow should terminate

##### `build_graph(model=None, policy_engine=None, judge=None)`

Build the LangGraph flow.

**Parameters:**

- `model`: The language model to use (defaults to StubModel)
- `policy_engine`: The policy engine to use for defense
- `judge`: The judge to use for evaluation

**Returns:**
A configured LangGraph Pregel instance

### 2. Defense (`rtz.defense`)

#### `Policy` Class

Defines a defense policy with pre-input, post-output, and tool-call rules.

**Methods:**

- `evaluate_pre_input(text: str) -> dict`: Evaluate input against pre-input rules
- `evaluate_post_output(text: str) -> dict`: Evaluate output against post-output rules
- `evaluate_tool_call(tool_name: str, args: dict) -> dict`: Evaluate tool calls against tool-call rules

#### `PolicyEngine` Class

Manages and applies defense policies.

**Methods:**

- `defend_input(text: str) -> dict`: Apply pre-input defenses
- `defend_output(text: str) -> dict`: Apply post-output defenses
- `check_tool_call(tool_name: str, args: dict) -> dict`: Check if a tool call is allowed

### 3. Judge (`rtz.judge`)

#### `RuleJudge` Class

Evaluates model outputs against predefined success criteria.

**Methods:**

- `evaluate(output: str, expected: str = None) -> dict`: Evaluate model output against criteria
- `add_pattern(pattern: str)`: Add a new pattern to match against
- `clear_patterns()`: Clear all patterns

### 4. Models (`rtz.models`)

#### `BaseModel` Class

Abstract base class for all model implementations.

**Methods:**

- `generate(prompt: str, **kwargs) -> str`: Generate text from a prompt
- `get_embeddings(text: str) -> list[float]`: Get embeddings for text

#### `StubModel` Class

A simple model implementation for testing.

**Methods:**

- `generate(prompt: str, **kwargs) -> str`: Echo back the input prompt

### 5. Attack (`rtz.attack`)

#### `BaseAttack` Class

Abstract base class for attack strategies.

**Methods:**

- `generate_prompt(scenario: dict) -> str`: Generate an attack prompt
- `evaluate_response(response: str) -> bool`: Evaluate if attack was successful

## Utilities (`rtz.utils`)

### `config` Module

Configuration loading and management.

### `logging_utils` Module

Logging configuration and utilities.

### `metrics` Module

Performance and evaluation metrics collection.

## Scripts (`rtz.scripts`)

### `cli` Module

Command-line interface for running tests and experiments.

## Examples

### Basic Usage

```python
from rtz.orchestration.langgraph_flow import build_graph
from rtz.defense import PolicyEngine, Policy
from rtz.judge import RuleJudge

# Create a policy engine with default policy
policy_engine = PolicyEngine(Policy(version=1, name="default"))

# Create a judge
judge = RuleJudge(patterns=[r"malicious"])

# Build and run the graph
graph = build_graph(policy_engine=policy_engine, judge=judge)
result = graph.invoke({
    "scenario": {"goal": "test"},
    "budget_usd": 0.10,
    "attempt": 0,
    "learner_state": {},
    "costs": {}
})
```

## Error Handling

All modules raise appropriate exceptions with descriptive error messages. Common exceptions include:

- `PolicyValidationError`: Raised when a policy is invalid
- `ModelError`: Raised when there's an error in model operations
- `AttackError`: Raised when an attack fails
- `DefenseError`: Raised when a defense mechanism fails

## Logging

The framework uses Python's built-in logging module with the following log levels:

- DEBUG: Detailed debug information
- INFO: General operational information
- WARNING: Non-critical issues
- ERROR: Critical issues
- CRITICAL: Severe errors that may prevent the application from running
